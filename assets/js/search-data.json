{
  
    
        "post0": {
            "title": "It's like Dark Souls meets Breath of the Wild",
            "content": "Nerdy Filler . I love games. I&#39;m not good at them, but I love them nonetheless. I spend a lot of time looking at metacritic, searching for the next game I wanna play. I wouldn&#39;t say I have a huge amount of time to trial games - so, whilst it&#39;s not life and death, it would be good to go into purchasing a game with some confidence I&#39;ll enjoy it. . Now, it&#39;s obvious that building a homemade recommender system for video games will always struggle up against what the Sony/Microsoft/Nintendo can build - these companies will have masses of user data, and should be able to build pretty strong collaborative filter type systems. . And also, this quick article isn&#39;t even going to start on that recommender system (why would I open myself up to judgement on the games I play??). What I want to do in here is talk about how we&#39;d go about creating some useful data, that could then be used in a recommender system. . Summarising the summaries . One of the best sites for exploring which games to play next, is metacritic. This collects multiple reviews from critics/users and aggregates these into ratings. They also provide summary information on games and this is where we&#39;ll collect and transform into useful features for games. . . There&#39;s a lot of useful data on that page, but we&#39;re going to focus solely on the summary for now and for ease we&#39;re going to collect ~50 games that have been released on the PS5 in the last year. Naturally with data like this, more is always better than less - but the process can remain the same. . Scraping Away . The first thing we need to do is to loop through a list of games, collecting the summary for each of these. I tend to lean towards doing this in a pandas dataframe (though there will be more efficient ways of storing this; I just come from an R background and it&#39;s my preference for exploration). There&#39;s a good article on scraping reviews from metacritic here which we have adapted to collect the summary instead. . game_name console_name rating_name blurb_long . 0 elden-ring | playstation-5 | 96 | A New World Created By Hidetaka Miyazaki And G... | . 1 the-stanley-parable-ultra-deluxe | playstation-5 | 89 | 2013&#39;s The stanley parable is a classic. Full ... | . 2 horizon-forbidden-west | playstation-5 | 88 | Join Aloy as she braves the Forbidden West – a... | . 3 gran-turismo-7 | playstation-5 | 87 | From classic vehicles and tracks to the reintr... | . 4 uncharted-legacy-of-thieves-collection | playstation-5 | 87 | The game looks absolutely stellar on PS5, and ... | . Turning text into something useful . This provides us with a single column for the whole summary, which is great - but not really that useful for any future processes. . We&#39;ll treat this text data with the following steps: . Cleaning - we want to turn the data into lowercase to ensure each of the records are consistent. We don&#39;t want a situation where our code sees &quot;classic&quot; and &quot;Classic&quot; as two different words | Tokenisation - this is a way of splitting long text-objects into distinct tokens. The simplest example is single word tokenisation, where we can take a sentence &#39;this is a game&#39; and split into a list of words [&#39;this&#39;, &#39;is&#39;, &#39;a&#39;, &#39;game&#39;] | Lemmatisation - this process will ensure that tenses of words are meaningless, and words such as &#39;run&#39;, &#39;ran&#39; and &#39;running&#39; will all match to the same root word | Vectorisation - once we&#39;ve split the words into tokens, we can then transform the data into a matrix of token occurences. At this step we&#39;ll also strip out domain specific stop words (done via max_df) and words that are completely unique to few records (done via min_df) | . At the end of that process we have something like this: . game_name console_name rating_name blurb_long 3d ability about across action adventure ... who will wit with within world year you your zone . 0 elden-ring | playstation-5 | 96 | A New World Created By Hidetaka Miyazaki And G... | 0 | 0 | 0 | 0 | 0 | 1 | ... | 0 | 0 | 0 | 1 | 1 | 1 | 0 | 0 | 0 | 1 | . 1 the-stanley-parable-ultra-deluxe | playstation-5 | 89 | 2013&#39;s The stanley parable is a classic. Full ... | 0 | 0 | 1 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 1 | 1 | 0 | . 2 horizon-forbidden-west | playstation-5 | 88 | Join Aloy as she braves the Forbidden West – a... | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 1 | 0 | 1 | 0 | 1 | 0 | 0 | . 3 gran-turismo-7 | playstation-5 | 87 | From classic vehicles and tracks to the reintr... | 1 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 4 uncharted-legacy-of-thieves-collection | playstation-5 | 87 | The game looks absolutely stellar on PS5, and ... | 1 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 1 | 0 | 0 | . 5 rows × 329 columns . Reducing dimensionality . We end up with a whopping 325 additional columns which all represent a binary value as to whether that token appears in the summary text. This is quite a lot of tokens, and truthfully some of them will still be pretty familiar and interchangeable - in order to reduce this further we can use a dimension reduction technique. There are many, we&#39;ll stick to a relatively simple Principal Components piece here - but may be worth investigating more graphical solutions (e.g. tSNE and uMAP). . The idea behind this is to take those 325 columns and reduce them into, say, 2 components which can explain the majority of the variance between them. This is useful when starting to measure distance, where a simple Euclidean distance metric will suffer dramatically from the curse of dimensionality. . But okay, what should I actually buy next? . So with this data we can now start making a stab at measuring how similar two games are to one another. Let&#39;s take an example. My favourite game this year is probably Elden Ring, but I&#39;ve completed it now and whilst it&#39;s tempting to just start a new save, let&#39;s say I want to try something different - based on the summaries given on metacritic what would this simple method suggest? . So we have these two principal components, and when we plot a few games you can visually see the distance between a set of games. Take below, we can see that Elden Ring is closer to Sifu than it is Gran Turismo 7. And this makes sense, Sifu is much closer in genre (and difficulty!) than GT7 and you can kind of reason similarities between the two. . We can even measure &#39;similarity&#39; as just 1 over the euclidean distance between the two points. Therefore for Elden Ring we can ask for the most similar game we can find. . from scipy.spatial.distance import euclidean, pdist, squareform def similarity_func(u, v): return 1/(1+euclidean(u,v)) dists = pdist(critic_df[[&#39;pca_1&#39;, &#39;pca_2&#39;]], similarity_func) sim_df = pd.DataFrame(squareform(dists), columns=critic_df[&#39;game_name&#39;], index=critic_df[&#39;game_name&#39;]) sim_df[&#39;elden-ring&#39;] . game_name elden-ring 0.000000 the-stanley-parable-ultra-deluxe 0.178060 horizon-forbidden-west 0.414328 gran-turismo-7 0.486106 uncharted-legacy-of-thieves-collection 0.394535 destiny-2-the-witch-queen 0.506614 crusader-kings-iii-console-edition 0.381153 olliolli-world 0.176593 lego-star-wars-the-skywalker-saga 0.314269 this-war-of-mine-final-cut 0.184829 grand-theft-auto-v 0.358598 far-changing-tides 0.565858 sifu 0.620281 sonic-origins 0.550740 assetto-corsa-competizione 0.421488 road-96 0.355987 the-king-of-fighters-xv 0.295990 souldiers 0.719638 chernobylite 0.110320 mlb-the-show-22 0.534619 grid-legends 0.473051 relayer 0.678840 sniper-elite-5 0.396560 wwe-2k22 0.534873 vampire-the-masqueradebloodhunt 0.562691 the-ascent 0.708334 motogp-22 0.544457 salt-and-sacrifice 0.413128 lost-judgment-the-kaito-files 0.600030 dying-light-2-stay-human 0.155081 tiny-tinas-wonderlands 0.517218 eiyuden-chronicle-rising 0.366368 ghostwire-tokyo 0.492754 cyberpunk-2077 0.677128 monster-energy-supercrossthe-official-videogame-5 0.637552 tom-clancys-rainbow-six-extraction 0.371601 the-quarry 0.485407 submerged-hidden-depths 0.503561 evil-dead-the-game 0.211463 stranger-of-paradise-final-fantasy-origin 0.800892 martha-is-dead 0.519761 anno-mutationem 0.376495 a-memoir-blue 0.375061 the-centennial-case-a-shijima-story 0.260546 assassins-creed-valhalla-dawn-of-ragnarok 0.521027 Name: elden-ring, dtype: float64 . . So what game is next on my list? Well apparently this, but I&#39;m really not sure... . . Is it even good? . Okay, so the end result was a bit disappointing - I&#39;m glad it didn&#39;t give me WWE 2k22 but it&#39;s still underwhelming. Were we looking to improve this we&#39;ve got a lot of different avenues we can explore: . Mo&#39; games - we&#39;re only looking at &lt;50 bestselling games on the PS5 from the current year, which is very limited in terms of sample of breadth. | Mo&#39; data - we&#39;re also only extracting the summary, we will definitely improve the process if we add additional features. On each game&#39;s homepage we have additional data like genre, rating, even developer - which would give us more belief in features used | Better techniques - everything we&#39;ve done here is pretty simple. There are many areas where we can improve and optimise - Named-entity Recognition may aid us in removing unhelpful nouns from the summary text; more diverse dimension reduction techniques could help us more accurately transpose the huge text data into more usable features; similarly NLP transformers could do this job for us in a more robust way, and could help with the lack of data. | . Overall I think this gives some indication of the potential of freely available data we could use. One fear I have before going too far down this route, is how well text-processing techniques can deal with &quot;creative&quot; text data - I can see how a model can easily learn a relationship between more structured and consistent text (e.g. categorical labels, commerce receipts, chatbot data) where the text is chosen to be as clear and concise as possible. With reviews and summaries, critics will be encouraged to write creatively - to appeal to a human rather than be understood by a machine, and this could be where models find it increasingly difficult to pick out context (well, maybe AI will be fine? PLEASE? I HOPE?). .",
            "url": "https://ffmmbb.github.io/franalytics/text-extraction/code/2022/06/26/games-and-reviews.html",
            "relUrl": "/text-extraction/code/2022/06/26/games-and-reviews.html",
            "date": " • Jun 26, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Is this a Garden?",
            "content": "Why do you even care? . Recently we’ve been looking to buy a property, obviously we have a set idea of what kind of property we want; what our deal-breakers are; what our nice-to-haves are. Like most people, I imagine, in the UK our search starts on property search engines like RightMove or Zoopla. . This is where the fun starts. Whilst all engines have the same basic filters (area, bedrooms, price) it becomes much much more difficult to filter for the more detailed items (garden, floorplan ideals, types of blah), and whilst everywhere offers some degree of filtering; the level of detail varies, and the properties you’re shown do not exactly match what you believed when you filter. . Types of Recommendations . Before we go too deep into specifics around property, I want to talk a bit about the different types of recommender systems. . There are three main types of system: . Collaborative - an approach that bases recommendations based upon the actions of other users/myself | Content - an approach that bases recommendations on the attributes of items I’ve engaged with in the past | Knowledge - an approach that bases recommendations based on specific attributes provided by the user | . Users looking for property aren’t going to do this regularly, and may be looking for something different than the previous time they successfully purchased (upsizing/downsizing); so the optimal way of building a recommender system for property will be utilising knowledge based techniques. . Knowledge based filtering . The way this works for property searches will be a user gives you a list of specific filters for an item. The main three being: . Area | Price | Number of Bedrooms | . Then the search engine will filter results that match this criteria and expose them to the user. The ordering of results is where the search engine can play around in the recommendation space, often a user will be given the option of how to sort; else it may be popularity or a more fun complex recommender solution. . The user can further refine the results using additional filters. . Now this is where it becomes much more difficult - most of these filters are binary/categorical - but is this how they actually should work? Let’s think about garden. If I tick for a garden, am I expecting a front garden? back garden? direct access? communal/private?. An estate agent could easily argue for all of these being a garden (and maybe even just a balcony if they’re being especially tricky) but if a user is explicitly filtering for a garden, what are they expecting? Does the search engine have a sufficient signal to know? . Importance . I’ve already touched on it briefly, but is there an element of soft-filtering that a user can do instead. I may prefer to have a garden, but want to see other properties too because it’s not a deal-breaker. This is one of the areas which shouldn’t change the content of results; but the ordering. I’ve seen some new (well, to me anyway) aggregators do this quite well. . OnTheMarket has the concept of a ‘Wish List’ where it won’t exclude results from showing; but will flag the ones that match criteria on the wishlist. This is useful, a user doesn’t need to re-search to expand their result set, but it still feels refined. . Quality of metadata . A big big issue is the actual quality of data a search engine has on a property, and where this has come from. Assuming everything is inputted by estate agents, then there is a problem of agents manipulating and exaggerating properties to make sure they appear in as many searches as possible. If I know that a search engine utilises garden as a filter, why wouldn’t I say a property has a garden if there was access to a communal one? It’s not a lie, and it will increase how many users see my property. . As AI systems progress, it could become more commonplace for these features to be extracted from other sources: photos, free text, floor plans &amp; blueprints. But there are similar issues here (we all know how good estate agents are at taking flattering photos) and unless there is a way of extracting data from sources without bias (neither sellers or buyers) then even this will struggle to provide accurate and high quality attributes for properties. . So how can we fix it? . With great difficulty, probably. There’s two main areas I would focus on: . The right data . Data quality will always be an issue, property search engines need a way of measuring how accurate given data is for a property - with the amount of properties listed on these sites, and the maturity of work in the area, it wouldn’t be too difficult to build a predictive model of how likely a property is to sell given all the attributes provided, and therefore any anomalous behaviour (a property taking too long to sell than expected) could be a reflection of the accuracy of certain attributes provided. . Once we have that, I’d then lean towards combining these supplied features with more programmatically extracted features (through image detection - both property images and floorplans and topic extraction from property descriptions), potentially with the supplied features weighted by how accurate we believe they are. . Conversational &amp; Responsive engines . Once we have the right data, we can start exploring ways of presenting that data to the customer. There’s a few things you could do here: . Maintain the same ecosystem and just respond to browsing behaviour, a positive interaction on these sites will be defined as a click through to contact the agent - once we have that you can match and find similar properties based on these collected features. | I love the idea of conversational recommender systems, buying/renting property is such a massive purchase that you almost want to be able to explain exactly what you want. I imagine most people will want to do this to a human, but I’d be happy with some clever AI using NLP techniques to take my poorly written explanation of what I want to match to similar properties based on the feature space it has on properties | I would also combine the above with responsive engine (e.g. “I like this flat but on the ground floor”) would be amazing. Tech companies used to describe themselves as “uber for…“, and then that became “tinder for…” - but there’s value in that type of system. You’re asking the user to provide explict binary feedback (whereas for property searches this is unary) and you can learn what’s good AND bad for a user. | . Measurement . I’m glad I don’t work in this space because I would be a pain when talking about measurement. In an ideal world the optimal metric you would have is whether or not that customer liked the property enough to make an offer. The only explicit action you have is whether or not a user enquired about the property - this is just a unary signal (you cannot infer they didn’t like everything they did not enquire about) and it’s not a signal that the property was an actual match. Interestingly success could be defined by a user not coming back and making further enquiries, but it’s then difficult to infer: . what property was the successful property - you’d imagine a user can make multiple enquiries at once | whether or not it’s because they bought a property or because they got sick of searching | . All in all, it’s tough - I’d obviously lean on ‘Making an Enquiry’ to be a measure of success, but I’d never feel that confident. . I might be wrong . I may outline all of this and it’s actually just what companies are currently doing, or it offers little value - whilst property search engines provide the user a way of finding properties, the core of the business will be through it’s relationship with estate agents, so maybe the objective of recommender systems won’t be to find the right one property for the customer, but a breadth of properties that gets these consumers to multiple estate agents who can then lead the user to the perfect property. . But really, I just want to filter for a garden and only see properties with an actual garden, please. .",
            "url": "https://ffmmbb.github.io/franalytics/recommendations/2022/06/22/is-this-a-garden.html",
            "relUrl": "/recommendations/2022/06/22/is-this-a-garden.html",
            "date": " • Jun 22, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://ffmmbb.github.io/franalytics/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://ffmmbb.github.io/franalytics/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "A inquisitive Data Scientist who will blog more, for sure. .",
          "url": "https://ffmmbb.github.io/franalytics/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://ffmmbb.github.io/franalytics/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}